# Reduced simulation to isolate crash - no str_eq/lookup_keyword
try:
    from typing import List
except:
    pass

# Token types (reduced)
TT_IDENT: int = 59
TT_NUMBER: int = 60
TT_STRING: int = 61
TT_FSTRING: int = 62
TT_PLUS: int = 67
TT_COLON: int = 117
TT_NEWLINE: int = 130

def is_alpha(c: int) -> int:
    if c >= 65 and c <= 90:
        return 1
    if c >= 97 and c <= 122:
        return 1
    return 0

def is_digit(c: int) -> int:
    if c >= 48 and c <= 57:
        return 1
    return 0

def is_alnum(c: int) -> int:
    if is_alpha(c) == 1:
        return 1
    if is_digit(c) == 1:
        return 1
    return 0

class Token:
    def __init__(self, ttype: int, value, line: int, column: int):
        self.ttype: int = ttype
        self.value = value
        self.line: int = line
        self.column: int = column

class Lexer:
    def __init__(self, source: str):
        self.source: str = source
        self.pos: int = 0
        self.line: int = 1
        self.column: int = 1
        self.tokens: List[Token] = []

    def at_end(self) -> bool:
        return self.pos >= len(self.source)

    def current_char(self) -> char:
        return self.source[self.pos]

    def peek_char(self, offset: int = 1) -> char:
        pos: int = self.pos + offset
        if pos >= len(self.source):
            return ' '
        return self.source[pos]

    def advance(self):
        if self.pos < len(self.source):
            ch: char = self.source[self.pos]
            if ch == '\n':
                self.line = self.line + 1
                self.column = 1
            else:
                self.column = self.column + 1
            self.pos = self.pos + 1

    def skip_whitespace(self):
        while not self.at_end():
            ch: char = self.current_char()
            if ch == ' ' or ch == '\t':
                self.advance()
            else:
                break

    def read_number(self) -> Token:
        start_line: int = self.line
        start_col: int = self.column
        num: int = 0

        while not self.at_end():
            ch: char = self.current_char()
            if is_digit(ord(ch)) == 1:
                num = num * 10 + (ord(ch) - 48)
                self.advance()
            else:
                break

        return Token(TT_NUMBER, num, start_line, start_col)

    def read_string(self, is_fstring: bool = False) -> Token:
        start_line: int = self.line
        start_col: int = self.column
        quote: char = self.current_char()
        self.advance()

        string: str = ""
        while not self.at_end():
            ch: char = self.current_char()
            if ch == quote:
                self.advance()
                break
            string = string + ch
            self.advance()

        ttype: int = TT_FSTRING if is_fstring else TT_STRING
        return Token(ttype, string, start_line, start_col)

    def read_identifier(self) -> Token:
        start_line: int = self.line
        start_col: int = self.column
        ident: str = ""

        while not self.at_end():
            ch: char = self.current_char()
            if is_alnum(ord(ch)) == 1 or ch == '_':
                ident = ident + ch
                self.advance()
            else:
                break

        return Token(TT_IDENT, ident, start_line, start_col)

    def tokenize(self) -> List[Token]:
        while not self.at_end():
            ch: char = self.current_char()
            start_line: int = self.line
            start_col: int = self.column

            if ch == '\n':
                self.advance()
                self.tokens.append(Token(TT_NEWLINE, None, start_line, start_col))
                continue

            if ch == ' ' or ch == '\t':
                self.skip_whitespace()
                continue

            # F-strings
            pk = self.peek_char()
            if (ch == 'f' or ch == 'F') and (pk == '"' or pk == "'"):
                self.advance()
                self.tokens.append(self.read_string(is_fstring=True))
                continue

            if is_digit(ord(ch)) == 1:
                self.tokens.append(self.read_number())
                continue

            if ch == '"' or ch == "'":
                self.tokens.append(self.read_string())
                continue

            if is_alpha(ord(ch)) == 1 or ch == '_':
                self.tokens.append(self.read_identifier())
                continue

            if ch == ':':
                self.advance()
                self.tokens.append(Token(TT_COLON, None, start_line, start_col))
                continue

            if ch == '+':
                self.advance()
                self.tokens.append(Token(TT_PLUS, None, start_line, start_col))
                continue

            self.advance()

        return self.tokens

def main() -> int:
    code: str = "def foo"
    lexer: Lexer = Lexer(code)
    tokens: List[Token] = lexer.tokenize()
    n: int = len(tokens)
    if n == 2:
        print("OK\n")
    else:
        print("FAIL: ")
        c: char = chr(48 + n)
        print(c)
        print("\n")
    return 0
