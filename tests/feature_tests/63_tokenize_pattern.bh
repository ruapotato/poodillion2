# Test 63: Full tokenize pattern from lexer
try:
    from typing import List
except:
    pass

class Token:
    def __init__(self, ttype: int, value: str):
        self.ttype: int = ttype
        self.value: str = value

class Lexer:
    def __init__(self, source: str):
        self.source: str = source
        self.pos: int = 0
        self.tokens: List[Token] = []

    def at_end(self) -> bool:
        return self.pos >= len(self.source)

    def current_char(self) -> char:
        return self.source[self.pos]

    def advance(self):
        self.pos = self.pos + 1

    def read_identifier(self) -> str:
        ident: str = ""
        while not self.at_end():
            ch: char = self.current_char()
            # Check if alphanumeric or underscore
            c: int = ord(ch)
            is_alnum: bool = (c >= 97 and c <= 122) or (c >= 65 and c <= 90) or (c >= 48 and c <= 57) or ch == '_'
            if is_alnum:
                ident = ident + ch
                self.advance()
            else:
                break
        return ident

    def tokenize(self):
        while not self.at_end():
            ch: char = self.current_char()

            # Skip whitespace
            if ch == ' ' or ch == '\n':
                self.advance()
                continue

            # Read identifier if letter
            c: int = ord(ch)
            if (c >= 97 and c <= 122) or (c >= 65 and c <= 90) or ch == '_':
                ident: str = self.read_identifier()
                tok: Token = Token(1, ident)
                self.tokens.append(tok)
                continue

            # Unknown char - skip
            self.advance()

def main() -> int:
    print("Tokenize pattern test\n")

    lexer: Lexer = Lexer("hello world")
    lexer.tokenize()

    n: int = len(lexer.tokens)
    if n == 2:
        print("Token count: OK\n")
    else:
        print("Token count: FAIL\n")

    print("About to access token 0...\n")
    # Check first token
    t1: Token = lexer.tokens[0]
    print("Got t1\n")
    print("Accessing t1.value...\n")
    v1: str = t1.value
    print("Got v1\n")
    if v1 == "hello":
        print("Token 1: OK\n")
    else:
        print("Token 1: FAIL\n")

    # Check second token
    t2: Token = lexer.tokens[1]
    if t2.value == "world":
        print("Token 2: OK\n")
    else:
        print("Token 2: FAIL\n")

    print("Done\n")
    return 0
