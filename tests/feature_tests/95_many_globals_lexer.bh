# Test lexer pattern with many global constants (like real lexer)
try:
    from typing import List
except:
    pass

# Token types - similar count to real lexer
TT_DEF: int = 1
TT_CLASS: int = 2
TT_FROM: int = 3
TT_IMPORT: int = 4
TT_AS: int = 5
TT_RETURN: int = 6
TT_IF: int = 7
TT_ELIF: int = 8
TT_ELSE: int = 9
TT_WHILE: int = 10
TT_FOR: int = 11
TT_IN: int = 12
TT_BREAK: int = 13
TT_CONTINUE: int = 14
TT_PASS: int = 15
TT_WITH: int = 16
TT_RAISE: int = 17
TT_TRY: int = 18
TT_EXCEPT: int = 19
TT_FINALLY: int = 20
TT_LAMBDA: int = 21
TT_YIELD: int = 22
TT_ASYNC: int = 23
TT_AWAIT: int = 24
TT_EXTERN: int = 25
TT_ASM: int = 26
TT_DEFER: int = 27
TT_MATCH: int = 28
TT_FINAL: int = 29
TT_PTR: int = 30
TT_LIST: int = 31
TT_DICT: int = 32
TT_TUPLE: int = 33
TT_OPTIONAL: int = 34
TT_INT8: int = 35
TT_INT16: int = 36
TT_INT32: int = 37
TT_INT64: int = 38
TT_UINT8: int = 39
TT_UINT16: int = 40
TT_UINT32: int = 41
TT_UINT64: int = 42
TT_FLOAT32: int = 43
TT_FLOAT64: int = 44
TT_BOOL: int = 45
TT_CHAR: int = 46
TT_STR: int = 47
TT_BYTES: int = 48
TT_INT: int = 49
TT_FLOAT: int = 50
TT_ARRAY: int = 51
TT_REF: int = 52
TT_ENUM: int = 53
TT_AUTO: int = 54
TT_DATACLASS: int = 55
TT_ISINSTANCE: int = 56
TT_FIELD: int = 57
TT_PROPERTY: int = 58
TT_IDENT: int = 59
TT_NUMBER: int = 60
TT_STRING: int = 61
TT_FSTRING: int = 62
TT_CHAR_LIT: int = 63
TT_TRUE: int = 64
TT_FALSE: int = 65
TT_NONE: int = 66
TT_PLUS: int = 67
TT_MINUS: int = 68
TT_STAR: int = 69
TT_SLASH: int = 70
TT_EQUALS: int = 74
TT_COLON: int = 117
TT_NEWLINE: int = 130

def is_alpha(c: int) -> int:
    if c >= 65 and c <= 90:
        return 1
    if c >= 97 and c <= 122:
        return 1
    return 0

class Token:
    def __init__(self, ttype: int, value, line: int, column: int):
        self.ttype: int = ttype
        self.value = value
        self.line: int = line
        self.column: int = column

class Lexer:
    def __init__(self, source: str):
        self.source: str = source
        self.pos: int = 0
        self.line: int = 1
        self.column: int = 1
        self.tokens: List[Token] = []

    def at_end(self) -> bool:
        return self.pos >= len(self.source)

    def current_char(self) -> char:
        return self.source[self.pos]

    def advance(self):
        if self.pos < len(self.source):
            ch: char = self.source[self.pos]
            if ch == '\n':
                self.line = self.line + 1
                self.column = 1
            else:
                self.column = self.column + 1
            self.pos = self.pos + 1

    def tokenize(self) -> List[Token]:
        while not self.at_end():
            ch: char = self.current_char()
            start_line: int = self.line
            start_col: int = self.column

            if ch == ' ':
                self.advance()
                continue

            if ch == '\n':
                self.advance()
                self.tokens.append(Token(TT_NEWLINE, None, start_line, start_col))
                continue

            if is_alpha(ord(ch)) == 1:
                ident: str = ""
                while not self.at_end():
                    c: char = self.current_char()
                    if is_alpha(ord(c)) == 1:
                        ident = ident + c
                        self.advance()
                    else:
                        break
                self.tokens.append(Token(TT_IDENT, ident, start_line, start_col))
                continue

            if ch == ':':
                self.advance()
                self.tokens.append(Token(TT_COLON, None, start_line, start_col))
                continue

            if ch == '=':
                self.advance()
                self.tokens.append(Token(TT_EQUALS, None, start_line, start_col))
                continue

            self.advance()

        return self.tokens

def main() -> int:
    code: str = "x: int = y"
    lexer: Lexer = Lexer(code)
    tokens: List[Token] = lexer.tokenize()
    n: int = len(tokens)
    # x, :, int, =, y = 5 tokens
    if n == 5:
        print("OK\n")
    else:
        print("FAIL: count=")
        c: char = chr(48 + n)
        print(c)
        print("\n")
    return 0
