# Test 55: Lexer simulation (closer to actual lexer.py)
try:
    from typing import List
except:
    pass

def is_digit(c: int) -> int:
    if c >= 48 and c <= 57:
        return 1
    return 0

def is_alpha(c: int) -> int:
    if c >= 65 and c <= 90:
        return 1
    if c >= 97 and c <= 122:
        return 1
    return 0

class Token:
    def __init__(self, kind: int, value: str, line: int, col: int):
        self.kind: int = kind
        self.value: str = value
        self.line: int = line
        self.col: int = col

class Lexer:
    def __init__(self, source: str):
        self.source: str = source
        self.pos: int = 0
        self.line: int = 1
        self.column: int = 0
        self.tokens: List[Token] = []

    def at_end(self) -> bool:
        n: int = len(self.source)
        return self.pos >= n

    def current_char(self) -> char:
        return self.source[self.pos]

    def peek_char(self) -> char:
        next_pos: int = self.pos + 1
        n: int = len(self.source)
        if next_pos < n:
            return self.source[next_pos]
        return '\0'

    def advance(self):
        self.pos = self.pos + 1
        self.column = self.column + 1

    def skip_whitespace(self):
        while not self.at_end():
            ch: char = self.current_char()
            if ch == ' ' or ch == '\t':
                self.advance()
            elif ch == '\n':
                self.line = self.line + 1
                self.column = 0
                self.advance()
            else:
                break

    def add_token(self, kind: int, value: str):
        t: Token = Token(kind, value, self.line, self.column)
        self.tokens.append(t)

    def get_count(self) -> int:
        return len(self.tokens)

    def tokenize(self):
        while not self.at_end():
            self.skip_whitespace()
            if self.at_end():
                break

            ch: char = self.current_char()
            code: int = ord(ch)

            # Identifiers
            if is_alpha(code) == 1 or ch == '_':
                start: int = self.pos
                while not self.at_end():
                    c: char = self.current_char()
                    cd: int = ord(c)
                    if is_alpha(cd) == 1 or is_digit(cd) == 1 or c == '_':
                        self.advance()
                    else:
                        break
                self.add_token(1, "ident")
            # Digits
            elif is_digit(code) == 1:
                while not self.at_end():
                    c: char = self.current_char()
                    cd: int = ord(c)
                    if is_digit(cd) == 1:
                        self.advance()
                    else:
                        break
                self.add_token(2, "num")
            # Operators and punctuation
            elif ch == '+':
                self.advance()
                self.add_token(3, "+")
            elif ch == '=':
                self.advance()
                self.add_token(4, "=")
            elif ch == '(':
                self.advance()
                self.add_token(5, "(")
            elif ch == ')':
                self.advance()
                self.add_token(6, ")")
            else:
                self.advance()
                self.add_token(0, "?")

def main() -> int:
    print("Lexer sim test\n")

    lex: Lexer = Lexer("x = 1 + 2")
    lex.tokenize()

    n: int = lex.get_count()
    # x = 1 + 2 -> ident, =, num, +, num = 5 tokens
    if n == 5:
        print("Count: OK\n")
    else:
        print("Count: FAIL\n")

    print("Done\n")
    return 0
