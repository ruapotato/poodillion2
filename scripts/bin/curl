#!/usr/bin/pooscript
# curl - transfer data from URLs

if len(args) == 0:
    error("curl: no URL specified!")
    print("Usage: curl <url>")
    print("")
    print("Available sites:")
    print("  - news.poo")
    print("  - hackernews.poo")
    print("  - secrets.poo")
    print("  - bank.poo")
    print("  - shop.poo")
    print("  - weather.poo")
    print("  - wiki.poo")
    print("")
    print("Try: curl news.poo")
    exit(1)

url = args[0]

# Simple URL parsing
# Remove http:// or https:// if present
if url.startswith('http://'):
    url = url[7:]
elif url.startswith('https://'):
    url = url[8:]

# Remove trailing slashes
url = url.rstrip('/')

# Map URLs to files in /www/
# Try to find the website content
www_path = f"/www/{url}"

# Check if the file exists
if vfs.exists(www_path):
    try:
        content = vfs.read(www_path)
        print(content)
    except RuntimeError as e:
        error(f"curl: ({url}) Failed to read content")
        exit(1)
else:
    # Try common variations
    if not url.endswith('.poo') and not url.endswith('.html'):
        # Try adding .poo extension
        www_path_poo = f"/www/{url}.poo"
        if vfs.exists(www_path_poo):
            try:
                content = vfs.read(www_path_poo)
                print(content)
                exit(0)
            except RuntimeError:
                pass

        # Try adding .html extension
        www_path_html = f"/www/{url}.html"
        if vfs.exists(www_path_html):
            try:
                content = vfs.read(www_path_html)
                print(content)
                exit(0)
            except RuntimeError:
                pass

    # URL not found
    error(f"curl: ({url}) Could not resolve host")
    print("")
    print("Available sites:")
    print("  - news.poo")
    print("  - hackernews.poo")
    print("  - secrets.poo")
    print("  - bank.poo")
    print("  - shop.poo")
    print("  - weather.poo")
    print("  - wiki.poo")
    print("")
    print("Try: curl news.poo")
    exit(1)

exit(0)
