# Lexer for Brainhair Self-Hosted Compiler
#
# Converts source code text into a stream of tokens.
# Uses a simple hand-written lexer for efficiency.

# ============================================================================
# Lexer State Structure
# Layout (24 bytes):
#   source: ptr     - Source code string (offset 0)
#   pos: int32      - Current position in source (offset 4)
#   length: int32   - Length of source (offset 8)
#   line: int32     - Current line number (offset 12)
#   col: int32      - Current column number (offset 16)
#   arena: ptr      - Arena for string allocations (offset 20)
# ============================================================================

const LEXER_SOURCE_OFFSET: int32 = 0
const LEXER_POS_OFFSET: int32 = 4
const LEXER_LENGTH_OFFSET: int32 = 8
const LEXER_LINE_OFFSET: int32 = 12
const LEXER_COL_OFFSET: int32 = 16
const LEXER_ARENA_OFFSET: int32 = 20
const LEXER_SIZE: int32 = 24

# Memory allocation for lexer strings
const SYS_mmap: int32 = 90
const PROT_READ: int32 = 1
const PROT_WRITE: int32 = 2
const MAP_PRIVATE: int32 = 2
const MAP_ANONYMOUS: int32 = 32

extern proc syscall6(num: int32, arg1: int32, arg2: int32, arg3: int32, arg4: int32, arg5: int32, arg6: int32): int32

proc lex_alloc(size: int32): ptr uint8 =
    var mem: int32 = syscall6(SYS_mmap, 0, size,
                              PROT_READ | PROT_WRITE,
                              MAP_PRIVATE | MAP_ANONYMOUS, -1, 0)
    if mem < 0:
        return cast[ptr uint8](0)
    return cast[ptr uint8](mem)

# ============================================================================
# Lexer Accessors
# ============================================================================

proc lexer_source(lex: ptr uint8): ptr uint8 =
    var l32: ptr int32 = cast[ptr int32](lex)
    return cast[ptr uint8](l32[0])

proc lexer_pos(lex: ptr uint8): int32 =
    var l32: ptr int32 = cast[ptr int32](lex)
    return l32[1]

proc lexer_set_pos(lex: ptr uint8, pos: int32) =
    var l32: ptr int32 = cast[ptr int32](lex)
    l32[1] = pos

proc lexer_length(lex: ptr uint8): int32 =
    var l32: ptr int32 = cast[ptr int32](lex)
    return l32[2]

proc lexer_line(lex: ptr uint8): int32 =
    var l32: ptr int32 = cast[ptr int32](lex)
    return l32[3]

proc lexer_set_line(lex: ptr uint8, line: int32) =
    var l32: ptr int32 = cast[ptr int32](lex)
    l32[3] = line

proc lexer_col(lex: ptr uint8): int32 =
    var l32: ptr int32 = cast[ptr int32](lex)
    return l32[4]

proc lexer_set_col(lex: ptr uint8, col: int32) =
    var l32: ptr int32 = cast[ptr int32](lex)
    l32[4] = col

# ============================================================================
# Lexer Initialization
# ============================================================================

proc lexer_init(lex: ptr uint8, source: ptr uint8, length: int32) =
    var l32: ptr int32 = cast[ptr int32](lex)
    l32[0] = cast[int32](source)
    l32[1] = 0      # pos
    l32[2] = length # length
    l32[3] = 1      # line
    l32[4] = 1      # col
    l32[5] = 0      # arena (unused for now)

# ============================================================================
# Character Classification
# ============================================================================

proc is_alpha(c: uint8): bool =
    if c >= 65 and c <= 90:
        return true  # A-Z
    if c >= 97 and c <= 122:
        return true  # a-z
    if c == 95:
        return true  # underscore
    return false

proc is_digit(c: uint8): bool =
    return c >= 48 and c <= 57  # 0-9

proc is_alnum(c: uint8): bool =
    return is_alpha(c) or is_digit(c)

proc is_whitespace(c: uint8): bool =
    return c == 32 or c == 9 or c == 13  # space, tab, CR (not newline)

proc is_hex_digit(c: uint8): bool =
    if is_digit(c):
        return true
    if c >= 65 and c <= 70:
        return true  # A-F
    if c >= 97 and c <= 102:
        return true  # a-f
    return false

proc hex_value(c: uint8): int32 =
    if c >= 48 and c <= 57:
        return cast[int32](c) - 48  # 0-9
    if c >= 65 and c <= 70:
        return cast[int32](c) - 55  # A-F
    if c >= 97 and c <= 102:
        return cast[int32](c) - 87  # a-f
    return 0

# ============================================================================
# Lexer Helper Functions
# ============================================================================

# Peek at current character without advancing
proc lexer_peek(lex: ptr uint8): uint8 =
    var pos: int32 = lexer_pos(lex)
    var length: int32 = lexer_length(lex)
    if pos >= length:
        return 0  # EOF

    var source: ptr uint8 = lexer_source(lex)
    return source[pos]

# Peek at character at offset
proc lexer_peek_at(lex: ptr uint8, offset: int32): uint8 =
    var pos: int32 = lexer_pos(lex) + offset
    var length: int32 = lexer_length(lex)
    if pos >= length:
        return 0

    var source: ptr uint8 = lexer_source(lex)
    return source[pos]

# Advance by one character
proc lexer_advance(lex: ptr uint8) =
    var c: uint8 = lexer_peek(lex)
    var pos: int32 = lexer_pos(lex)
    var col: int32 = lexer_col(lex)

    lexer_set_pos(lex, pos + 1)

    if c == 10:  # newline
        lexer_set_line(lex, lexer_line(lex) + 1)
        lexer_set_col(lex, 1)
    else:
        lexer_set_col(lex, col + 1)

# Skip whitespace (but not newlines)
proc lexer_skip_whitespace(lex: ptr uint8) =
    while is_whitespace(lexer_peek(lex)):
        lexer_advance(lex)

# Skip comment (from # to end of line)
proc lexer_skip_comment(lex: ptr uint8) =
    while true:
        var c: uint8 = lexer_peek(lex)
        if c == 0 or c == 10:
            break
        lexer_advance(lex)

# ============================================================================
# Token Types (imported from tokens.bh)
# ============================================================================

const TOK_EOF: int32 = 0
const TOK_IDENT: int32 = 1
const TOK_INT_LIT: int32 = 2
const TOK_STRING_LIT: int32 = 3
const TOK_CHAR_LIT: int32 = 4

const TOK_INT8: int32 = 10
const TOK_INT16: int32 = 11
const TOK_INT32: int32 = 12
const TOK_UINT8: int32 = 13
const TOK_UINT16: int32 = 14
const TOK_UINT32: int32 = 15
const TOK_BOOL: int32 = 16
const TOK_CHAR: int32 = 17
const TOK_PTR: int32 = 18
const TOK_ARRAY: int32 = 19

const TOK_IF: int32 = 20
const TOK_ELIF: int32 = 21
const TOK_ELSE: int32 = 22
const TOK_WHILE: int32 = 23
const TOK_FOR: int32 = 24
const TOK_BREAK: int32 = 25
const TOK_CONTINUE: int32 = 26
const TOK_RETURN: int32 = 27

const TOK_PROC: int32 = 30
const TOK_VAR: int32 = 31
const TOK_CONST: int32 = 32
const TOK_TYPE: int32 = 33
const TOK_EXTERN: int32 = 34

const TOK_TRUE: int32 = 40
const TOK_FALSE: int32 = 41
const TOK_NIL: int32 = 42

const TOK_AND: int32 = 50
const TOK_OR: int32 = 51
const TOK_NOT: int32 = 52
const TOK_DIV: int32 = 53
const TOK_MOD: int32 = 54

const TOK_CAST: int32 = 60
const TOK_ADDR: int32 = 61
const TOK_DISCARD: int32 = 62
const TOK_OBJECT: int32 = 63

const TOK_PLUS: int32 = 70
const TOK_MINUS: int32 = 71
const TOK_STAR: int32 = 72
const TOK_SLASH: int32 = 73
const TOK_PERCENT: int32 = 74

const TOK_EQ: int32 = 80
const TOK_NE: int32 = 81
const TOK_LT: int32 = 82
const TOK_LE: int32 = 83
const TOK_GT: int32 = 84
const TOK_GE: int32 = 85

const TOK_AMPERSAND: int32 = 90
const TOK_PIPE: int32 = 91
const TOK_CARET: int32 = 92
const TOK_TILDE: int32 = 93
const TOK_SHL: int32 = 94
const TOK_SHR: int32 = 95

const TOK_ASSIGN: int32 = 100

const TOK_LPAREN: int32 = 110
const TOK_RPAREN: int32 = 111
const TOK_LBRACKET: int32 = 112
const TOK_RBRACKET: int32 = 113
const TOK_LBRACE: int32 = 114
const TOK_RBRACE: int32 = 115
const TOK_COMMA: int32 = 116
const TOK_COLON: int32 = 117
const TOK_DOT: int32 = 118
const TOK_NEWLINE: int32 = 119

# Token structure offsets
const TOKEN_TYPE_OFFSET: int32 = 0
const TOKEN_LINE_OFFSET: int32 = 4
const TOKEN_COL_OFFSET: int32 = 8
const TOKEN_VALUE_OFFSET: int32 = 12
const TOKEN_STR_OFFSET: int32 = 16
const TOKEN_SIZE: int32 = 20

# ============================================================================
# Token Helpers
# ============================================================================

proc token_init(tok: ptr uint8, typ: int32, line: int32, col: int32) =
    var t32: ptr int32 = cast[ptr int32](tok)
    t32[0] = typ
    t32[1] = line
    t32[2] = col
    t32[3] = 0
    t32[4] = 0

proc token_set_value(tok: ptr uint8, value: int32) =
    var t32: ptr int32 = cast[ptr int32](tok)
    t32[3] = value

proc token_set_str(tok: ptr uint8, str: ptr uint8) =
    var t32: ptr int32 = cast[ptr int32](tok)
    t32[4] = cast[int32](str)

# ============================================================================
# Keyword Lookup
# ============================================================================

proc str_eq(s1: ptr uint8, s2: ptr uint8): bool =
    var i: int32 = 0
    while true:
        if s1[i] != s2[i]:
            return false
        if s1[i] == 0:
            return true
        i = i + 1
    return false

proc lookup_keyword(name: ptr uint8): int32 =
    if str_eq(name, cast[ptr uint8]("int8")):
        return TOK_INT8
    if str_eq(name, cast[ptr uint8]("int16")):
        return TOK_INT16
    if str_eq(name, cast[ptr uint8]("int32")):
        return TOK_INT32
    if str_eq(name, cast[ptr uint8]("uint8")):
        return TOK_UINT8
    if str_eq(name, cast[ptr uint8]("uint16")):
        return TOK_UINT16
    if str_eq(name, cast[ptr uint8]("uint32")):
        return TOK_UINT32
    if str_eq(name, cast[ptr uint8]("bool")):
        return TOK_BOOL
    if str_eq(name, cast[ptr uint8]("char")):
        return TOK_CHAR
    if str_eq(name, cast[ptr uint8]("ptr")):
        return TOK_PTR
    if str_eq(name, cast[ptr uint8]("array")):
        return TOK_ARRAY
    if str_eq(name, cast[ptr uint8]("if")):
        return TOK_IF
    if str_eq(name, cast[ptr uint8]("elif")):
        return TOK_ELIF
    if str_eq(name, cast[ptr uint8]("else")):
        return TOK_ELSE
    if str_eq(name, cast[ptr uint8]("while")):
        return TOK_WHILE
    if str_eq(name, cast[ptr uint8]("for")):
        return TOK_FOR
    if str_eq(name, cast[ptr uint8]("break")):
        return TOK_BREAK
    if str_eq(name, cast[ptr uint8]("continue")):
        return TOK_CONTINUE
    if str_eq(name, cast[ptr uint8]("return")):
        return TOK_RETURN
    if str_eq(name, cast[ptr uint8]("proc")):
        return TOK_PROC
    if str_eq(name, cast[ptr uint8]("var")):
        return TOK_VAR
    if str_eq(name, cast[ptr uint8]("const")):
        return TOK_CONST
    if str_eq(name, cast[ptr uint8]("type")):
        return TOK_TYPE
    if str_eq(name, cast[ptr uint8]("extern")):
        return TOK_EXTERN
    if str_eq(name, cast[ptr uint8]("true")):
        return TOK_TRUE
    if str_eq(name, cast[ptr uint8]("false")):
        return TOK_FALSE
    if str_eq(name, cast[ptr uint8]("nil")):
        return TOK_NIL
    if str_eq(name, cast[ptr uint8]("and")):
        return TOK_AND
    if str_eq(name, cast[ptr uint8]("or")):
        return TOK_OR
    if str_eq(name, cast[ptr uint8]("not")):
        return TOK_NOT
    if str_eq(name, cast[ptr uint8]("div")):
        return TOK_DIV
    if str_eq(name, cast[ptr uint8]("mod")):
        return TOK_MOD
    if str_eq(name, cast[ptr uint8]("cast")):
        return TOK_CAST
    if str_eq(name, cast[ptr uint8]("addr")):
        return TOK_ADDR
    if str_eq(name, cast[ptr uint8]("discard")):
        return TOK_DISCARD
    if str_eq(name, cast[ptr uint8]("object")):
        return TOK_OBJECT
    return TOK_IDENT

# ============================================================================
# Scanning Functions
# ============================================================================

# Scan an identifier or keyword
proc lexer_scan_ident(lex: ptr uint8, tok: ptr uint8) =
    var line: int32 = lexer_line(lex)
    var col: int32 = lexer_col(lex)
    var source: ptr uint8 = lexer_source(lex)
    var start: int32 = lexer_pos(lex)

    # Scan alphanumeric characters
    while is_alnum(lexer_peek(lex)):
        lexer_advance(lex)

    var end_pos: int32 = lexer_pos(lex)
    var length: int32 = end_pos - start

    # Allocate and copy identifier string
    var str: ptr uint8 = lex_alloc(length + 1)
    var i: int32 = 0
    while i < length:
        str[i] = source[start + i]
        i = i + 1
    str[length] = 0

    # Lookup keyword
    var tok_type: int32 = lookup_keyword(str)

    token_init(tok, tok_type, line, col)
    token_set_str(tok, str)

# Scan an integer literal
proc lexer_scan_number(lex: ptr uint8, tok: ptr uint8) =
    var line: int32 = lexer_line(lex)
    var col: int32 = lexer_col(lex)
    var value: int32 = 0

    # Check for hex prefix
    if lexer_peek(lex) == 48 and (lexer_peek_at(lex, 1) == 120 or lexer_peek_at(lex, 1) == 88):
        # Hex number
        lexer_advance(lex)  # Skip 0
        lexer_advance(lex)  # Skip x

        while is_hex_digit(lexer_peek(lex)):
            value = value * 16 + hex_value(lexer_peek(lex))
            lexer_advance(lex)
    else:
        # Decimal number
        while is_digit(lexer_peek(lex)):
            value = value * 10 + (cast[int32](lexer_peek(lex)) - 48)
            lexer_advance(lex)

    token_init(tok, TOK_INT_LIT, line, col)
    token_set_value(tok, value)

# Scan a string literal
proc lexer_scan_string(lex: ptr uint8, tok: ptr uint8) =
    var line: int32 = lexer_line(lex)
    var col: int32 = lexer_col(lex)
    var source: ptr uint8 = lexer_source(lex)

    lexer_advance(lex)  # Skip opening quote

    var start: int32 = lexer_pos(lex)

    # Find end of string
    while lexer_peek(lex) != 34 and lexer_peek(lex) != 0:
        if lexer_peek(lex) == 92:  # backslash
            lexer_advance(lex)     # Skip escape char
        lexer_advance(lex)

    var end_pos: int32 = lexer_pos(lex)
    var length: int32 = end_pos - start

    # Allocate and copy string (with escape processing)
    var str: ptr uint8 = lex_alloc(length + 1)
    var i: int32 = 0
    var j: int32 = 0
    while i < length:
        var c: uint8 = source[start + i]
        if c == 92 and i + 1 < length:
            # Escape sequence
            i = i + 1
            var next: uint8 = source[start + i]
            if next == 110:  # \n
                str[j] = 10
            elif next == 116:  # \t
                str[j] = 9
            elif next == 114:  # \r
                str[j] = 13
            elif next == 48:   # \0
                str[j] = 0
            elif next == 92:   # \\
                str[j] = 92
            elif next == 34:   # \"
                str[j] = 34
            else:
                str[j] = next
        else:
            str[j] = c
        i = i + 1
        j = j + 1
    str[j] = 0

    lexer_advance(lex)  # Skip closing quote

    token_init(tok, TOK_STRING_LIT, line, col)
    token_set_str(tok, str)

# Scan a character literal
proc lexer_scan_char(lex: ptr uint8, tok: ptr uint8) =
    var line: int32 = lexer_line(lex)
    var col: int32 = lexer_col(lex)

    lexer_advance(lex)  # Skip opening quote

    var value: int32 = 0
    var c: uint8 = lexer_peek(lex)

    if c == 92:  # Escape sequence
        lexer_advance(lex)
        var next: uint8 = lexer_peek(lex)
        if next == 110:
            value = 10
        elif next == 116:
            value = 9
        elif next == 114:
            value = 13
        elif next == 48:
            value = 0
        elif next == 92:
            value = 92
        elif next == 39:
            value = 39
        else:
            value = cast[int32](next)
        lexer_advance(lex)
    else:
        value = cast[int32](c)
        lexer_advance(lex)

    lexer_advance(lex)  # Skip closing quote

    token_init(tok, TOK_CHAR_LIT, line, col)
    token_set_value(tok, value)

# ============================================================================
# Main Lexer Function
# ============================================================================

# Get next token
proc lexer_next(lex: ptr uint8, tok: ptr uint8) =
    # Skip whitespace and comments
    while true:
        lexer_skip_whitespace(lex)
        if lexer_peek(lex) == 35:  # Comment
            lexer_skip_comment(lex)
        else:
            break

    var line: int32 = lexer_line(lex)
    var col: int32 = lexer_col(lex)
    var c: uint8 = lexer_peek(lex)

    # EOF
    if c == 0:
        token_init(tok, TOK_EOF, line, col)
        return

    # Newline
    if c == 10:
        lexer_advance(lex)
        token_init(tok, TOK_NEWLINE, line, col)
        return

    # Identifier or keyword
    if is_alpha(c):
        lexer_scan_ident(lex, tok)
        return

    # Number
    if is_digit(c):
        lexer_scan_number(lex, tok)
        return

    # String literal
    if c == 34:
        lexer_scan_string(lex, tok)
        return

    # Character literal
    if c == 39:
        lexer_scan_char(lex, tok)
        return

    # Two-character operators
    var next: uint8 = lexer_peek_at(lex, 1)

    if c == 61 and next == 61:  # ==
        lexer_advance(lex)
        lexer_advance(lex)
        token_init(tok, TOK_EQ, line, col)
        return

    if c == 33 and next == 61:  # !=
        lexer_advance(lex)
        lexer_advance(lex)
        token_init(tok, TOK_NE, line, col)
        return

    if c == 60 and next == 61:  # <=
        lexer_advance(lex)
        lexer_advance(lex)
        token_init(tok, TOK_LE, line, col)
        return

    if c == 62 and next == 61:  # >=
        lexer_advance(lex)
        lexer_advance(lex)
        token_init(tok, TOK_GE, line, col)
        return

    if c == 60 and next == 60:  # <<
        lexer_advance(lex)
        lexer_advance(lex)
        token_init(tok, TOK_SHL, line, col)
        return

    if c == 62 and next == 62:  # >>
        lexer_advance(lex)
        lexer_advance(lex)
        token_init(tok, TOK_SHR, line, col)
        return

    # Single-character tokens
    lexer_advance(lex)

    if c == 43:
        token_init(tok, TOK_PLUS, line, col)
        return
    if c == 45:
        token_init(tok, TOK_MINUS, line, col)
        return
    if c == 42:
        token_init(tok, TOK_STAR, line, col)
        return
    if c == 47:
        token_init(tok, TOK_SLASH, line, col)
        return
    if c == 37:
        token_init(tok, TOK_PERCENT, line, col)
        return
    if c == 60:
        token_init(tok, TOK_LT, line, col)
        return
    if c == 62:
        token_init(tok, TOK_GT, line, col)
        return
    if c == 61:
        token_init(tok, TOK_ASSIGN, line, col)
        return
    if c == 38:
        token_init(tok, TOK_AMPERSAND, line, col)
        return
    if c == 124:
        token_init(tok, TOK_PIPE, line, col)
        return
    if c == 94:
        token_init(tok, TOK_CARET, line, col)
        return
    if c == 126:
        token_init(tok, TOK_TILDE, line, col)
        return
    if c == 40:
        token_init(tok, TOK_LPAREN, line, col)
        return
    if c == 41:
        token_init(tok, TOK_RPAREN, line, col)
        return
    if c == 91:
        token_init(tok, TOK_LBRACKET, line, col)
        return
    if c == 93:
        token_init(tok, TOK_RBRACKET, line, col)
        return
    if c == 123:
        token_init(tok, TOK_LBRACE, line, col)
        return
    if c == 125:
        token_init(tok, TOK_RBRACE, line, col)
        return
    if c == 44:
        token_init(tok, TOK_COMMA, line, col)
        return
    if c == 58:
        token_init(tok, TOK_COLON, line, col)
        return
    if c == 46:
        token_init(tok, TOK_DOT, line, col)
        return

    # Unknown character - return as EOF with error position
    token_init(tok, TOK_EOF, line, col)
