#!/usr/bin/env python3
"""
MIR to x86 Code Generator for Brainhair Compiler

This module translates Mid-Level IR (MIR) to x86 assembly code.
It performs register allocation and instruction selection.

Target: 32-bit x86 (ELF32) for BrainhairOS
"""

from typing import Dict, List, Optional, Set
from dataclasses import dataclass, field

from mir import (
    MIRModule, MIRFunction, MIRBasicBlock, MIRInstruction,
    MIRType, MIRAnyType, PointerMIRType, ArrayMIRType,
    MIRValue, MIRConstant, MIRVirtualReg, MIRParam, MIRGlobal,
    MIROp
)


@dataclass
class StackSlot:
    """Represents a stack allocation."""
    offset: int  # Offset from EBP (negative)
    size: int    # Size in bytes


class MIRToX86:
    """
    Translates MIR to x86-32 assembly.

    Uses a simple stack-based approach where all values are stored
    on the stack (no register allocation optimization yet).
    """

    def __init__(self, kernel_mode: bool = False):
        self.kernel_mode = kernel_mode
        self.output: List[str] = []

        # Value locations: value name -> stack offset from EBP
        self.value_locations: Dict[str, int] = {}

        # Current stack frame size
        self.stack_offset: int = 0

        # String literals
        self.string_literals: Dict[str, str] = {}
        self.string_counter: int = 0

        # Current function
        self.current_func: Optional[MIRFunction] = None

    def generate(self, module: MIRModule) -> str:
        """Generate x86 assembly from MIR module."""
        self.output = []

        self._emit("; Generated by Brainhair Compiler (MIR backend)")
        self._emit("bits 32")
        self._emit("")

        # Data section for string literals
        self._emit("section .data")

        # Generate string literals (collected during code generation)
        # Will be populated later

        self._emit("")
        self._emit("section .text")

        # Export symbols
        if not self.kernel_mode:
            self._emit("global _start")
        else:
            self._emit("global main")

        # Export all functions
        for name in module.functions:
            self._emit(f"global {name}")

        self._emit("")

        # Generate entry point
        if not self.kernel_mode:
            self._emit("_start:")
            self._emit("    call main")
            self._emit("    ; Exit with return value")
            self._emit("    mov ebx, eax")
            self._emit("    mov eax, 1")  # sys_exit
            self._emit("    int 0x80")
            self._emit("")

        # Generate all functions
        for func in module.functions.values():
            if not func.is_extern:
                self._generate_function(func)

        return "\n".join(self.output)

    def _emit(self, line: str) -> None:
        """Emit a line of assembly."""
        self.output.append(line)

    def _generate_function(self, func: MIRFunction) -> None:
        """Generate x86 code for a function."""
        self.current_func = func
        self.value_locations = {}
        self.stack_offset = 0

        self._emit(f"{func.name}:")
        self._emit("    push ebp")
        self._emit("    mov ebp, esp")

        # Calculate stack space needed
        stack_size = self._calculate_stack_size(func)
        if stack_size > 0:
            self._emit(f"    sub esp, {stack_size}")

        # Initialize parameter locations (positive offset from EBP)
        for i, param in enumerate(func.params):
            # Parameters are pushed right-to-left, so first param is at [ebp+8]
            offset = 8 + i * 4
            self.value_locations[param.name] = offset

        # Generate basic blocks
        for block in func.blocks:
            self._generate_block(block)

        self._emit("")

    def _calculate_stack_size(self, func: MIRFunction) -> int:
        """Calculate total stack space needed for function."""
        # Count all allocas and virtual registers
        count = 0
        for block in func.blocks:
            for inst in block.instructions:
                if inst.dest and inst.dest.name not in self.value_locations:
                    self.stack_offset -= 4
                    self.value_locations[inst.dest.name] = self.stack_offset
                    count += 1
                if inst.op == MIROp.ALLOCA:
                    # Additional space for alloca
                    count += 1

        return count * 4

    def _generate_block(self, block: MIRBasicBlock) -> None:
        """Generate x86 code for a basic block."""
        # Emit label (skip for entry block)
        if block.name != "entry":
            self._emit(f".{block.name}:")

        for inst in block.instructions:
            self._generate_instruction(inst)

    def _generate_instruction(self, inst: MIRInstruction) -> None:
        """Generate x86 code for an instruction."""
        if inst.op == MIROp.ALLOCA:
            self._gen_alloca(inst)
        elif inst.op == MIROp.LOAD:
            self._gen_load(inst)
        elif inst.op == MIROp.STORE:
            self._gen_store(inst)
        elif inst.op in {MIROp.ADD, MIROp.SUB, MIROp.MUL, MIROp.DIV, MIROp.MOD}:
            self._gen_arithmetic(inst)
        elif inst.op in {MIROp.AND, MIROp.OR, MIROp.XOR, MIROp.SHL, MIROp.SHR}:
            self._gen_bitwise(inst)
        elif inst.op == MIROp.NEG:
            self._gen_neg(inst)
        elif inst.op == MIROp.NOT:
            self._gen_not(inst)
        elif inst.op in {MIROp.EQ, MIROp.NE, MIROp.LT, MIROp.LE, MIROp.GT, MIROp.GE}:
            self._gen_comparison(inst)
        elif inst.op == MIROp.BR:
            self._gen_branch(inst)
        elif inst.op == MIROp.CONDBR:
            self._gen_cond_branch(inst)
        elif inst.op == MIROp.RET:
            self._gen_return(inst)
        elif inst.op == MIROp.CALL:
            self._gen_call(inst)
        elif inst.op == MIROp.CAST:
            self._gen_cast(inst)
        elif inst.op == MIROp.GEP:
            self._gen_gep(inst)
        elif inst.op == MIROp.PHI:
            # Phi nodes are handled during SSA deconstruction
            # For now, just load from the first incoming
            self._gen_phi(inst)

    def _get_value_location(self, value: MIRValue) -> str:
        """Get the memory location or immediate for a value."""
        if isinstance(value, MIRConstant):
            return str(value.value)

        name = value.name
        if name in self.value_locations:
            offset = self.value_locations[name]
            if offset > 0:
                return f"[ebp+{offset}]"
            else:
                return f"[ebp{offset}]"

        # Unknown value - should not happen
        return f"; ERROR: unknown value {name}"

    def _load_value_to_eax(self, value: MIRValue) -> None:
        """Load a value into EAX."""
        if isinstance(value, MIRConstant):
            self._emit(f"    mov eax, {value.value}")
        else:
            loc = self._get_value_location(value)
            self._emit(f"    mov eax, {loc}")

    def _store_eax_to_dest(self, dest: MIRValue) -> None:
        """Store EAX to destination."""
        if dest and dest.name in self.value_locations:
            loc = self._get_value_location(dest)
            self._emit(f"    mov {loc}, eax")

    def _gen_alloca(self, inst: MIRInstruction) -> None:
        """Generate alloca (stack allocation)."""
        # The space is already reserved in function prologue
        # Just record the location
        if inst.dest:
            # dest is a pointer to the allocated space
            loc = self._get_value_location(inst.dest)
            offset = self.value_locations.get(inst.dest.name, 0)
            # Store the address (lea)
            self._emit(f"    lea eax, [ebp{offset}]")
            self._emit(f"    mov {loc}, eax")

    def _gen_load(self, inst: MIRInstruction) -> None:
        """Generate load instruction."""
        if not inst.operands:
            return
        ptr = inst.operands[0]

        # Load pointer value
        self._load_value_to_eax(ptr)
        # Dereference
        self._emit("    mov eax, [eax]")
        # Store result
        self._store_eax_to_dest(inst.dest)

    def _gen_store(self, inst: MIRInstruction) -> None:
        """Generate store instruction."""
        if len(inst.operands) < 2:
            return
        value = inst.operands[0]
        ptr = inst.operands[1]

        # Load value
        self._load_value_to_eax(value)
        self._emit("    push eax")
        # Load pointer
        self._load_value_to_eax(ptr)
        self._emit("    mov ebx, eax")
        self._emit("    pop eax")
        # Store
        self._emit("    mov [ebx], eax")

    def _gen_arithmetic(self, inst: MIRInstruction) -> None:
        """Generate arithmetic instruction."""
        if len(inst.operands) < 2:
            return
        left = inst.operands[0]
        right = inst.operands[1]

        # Load left operand
        self._load_value_to_eax(left)
        self._emit("    push eax")

        # Load right operand
        self._load_value_to_eax(right)
        self._emit("    mov ebx, eax")
        self._emit("    pop eax")

        if inst.op == MIROp.ADD:
            self._emit("    add eax, ebx")
        elif inst.op == MIROp.SUB:
            self._emit("    sub eax, ebx")
        elif inst.op == MIROp.MUL:
            self._emit("    imul eax, ebx")
        elif inst.op == MIROp.DIV:
            self._emit("    cdq")  # Sign extend EAX into EDX:EAX
            self._emit("    idiv ebx")  # Result in EAX
        elif inst.op == MIROp.MOD:
            self._emit("    cdq")
            self._emit("    idiv ebx")
            self._emit("    mov eax, edx")  # Remainder in EDX

        self._store_eax_to_dest(inst.dest)

    def _gen_bitwise(self, inst: MIRInstruction) -> None:
        """Generate bitwise instruction."""
        if len(inst.operands) < 2:
            return
        left = inst.operands[0]
        right = inst.operands[1]

        self._load_value_to_eax(left)
        self._emit("    push eax")
        self._load_value_to_eax(right)
        self._emit("    mov ebx, eax")
        self._emit("    pop eax")

        if inst.op == MIROp.AND:
            self._emit("    and eax, ebx")
        elif inst.op == MIROp.OR:
            self._emit("    or eax, ebx")
        elif inst.op == MIROp.XOR:
            self._emit("    xor eax, ebx")
        elif inst.op == MIROp.SHL:
            self._emit("    mov ecx, ebx")
            self._emit("    shl eax, cl")
        elif inst.op == MIROp.SHR:
            self._emit("    mov ecx, ebx")
            self._emit("    shr eax, cl")

        self._store_eax_to_dest(inst.dest)

    def _gen_neg(self, inst: MIRInstruction) -> None:
        """Generate negation."""
        if not inst.operands:
            return
        self._load_value_to_eax(inst.operands[0])
        self._emit("    neg eax")
        self._store_eax_to_dest(inst.dest)

    def _gen_not(self, inst: MIRInstruction) -> None:
        """Generate logical not."""
        if not inst.operands:
            return
        self._load_value_to_eax(inst.operands[0])
        self._emit("    test eax, eax")
        self._emit("    sete al")
        self._emit("    movzx eax, al")
        self._store_eax_to_dest(inst.dest)

    def _gen_comparison(self, inst: MIRInstruction) -> None:
        """Generate comparison instruction."""
        if len(inst.operands) < 2:
            return
        left = inst.operands[0]
        right = inst.operands[1]

        self._load_value_to_eax(left)
        self._emit("    push eax")
        self._load_value_to_eax(right)
        self._emit("    mov ebx, eax")
        self._emit("    pop eax")
        self._emit("    cmp eax, ebx")

        # Set result based on comparison
        set_instr = {
            MIROp.EQ: "sete",
            MIROp.NE: "setne",
            MIROp.LT: "setl",
            MIROp.LE: "setle",
            MIROp.GT: "setg",
            MIROp.GE: "setge",
        }

        self._emit(f"    {set_instr[inst.op]} al")
        self._emit("    movzx eax, al")
        self._store_eax_to_dest(inst.dest)

    def _gen_branch(self, inst: MIRInstruction) -> None:
        """Generate unconditional branch."""
        if inst.true_block:
            self._emit(f"    jmp .{inst.true_block.name}")

    def _gen_cond_branch(self, inst: MIRInstruction) -> None:
        """Generate conditional branch."""
        if not inst.operands:
            return
        cond = inst.operands[0]

        self._load_value_to_eax(cond)
        self._emit("    test eax, eax")

        if inst.true_block and inst.false_block:
            self._emit(f"    jnz .{inst.true_block.name}")
            self._emit(f"    jmp .{inst.false_block.name}")

    def _gen_return(self, inst: MIRInstruction) -> None:
        """Generate return instruction."""
        if inst.operands:
            self._load_value_to_eax(inst.operands[0])

        self._emit("    mov esp, ebp")
        self._emit("    pop ebp")
        self._emit("    ret")

    def _gen_call(self, inst: MIRInstruction) -> None:
        """Generate function call."""
        # Push arguments in reverse order
        for arg in reversed(inst.args):
            self._load_value_to_eax(arg)
            self._emit("    push eax")

        # Call function
        self._emit(f"    call {inst.callee}")

        # Clean up arguments
        if inst.args:
            self._emit(f"    add esp, {len(inst.args) * 4}")

        # Store result
        self._store_eax_to_dest(inst.dest)

    def _gen_cast(self, inst: MIRInstruction) -> None:
        """Generate cast instruction."""
        if not inst.operands:
            return
        # For now, just copy the value (no actual conversion)
        self._load_value_to_eax(inst.operands[0])
        self._store_eax_to_dest(inst.dest)

    def _gen_gep(self, inst: MIRInstruction) -> None:
        """Generate get element pointer."""
        if len(inst.operands) < 2:
            return
        base = inst.operands[0]
        index = inst.operands[1]

        # Load base address
        self._load_value_to_eax(base)
        self._emit("    push eax")

        # Load index
        self._load_value_to_eax(index)
        # Multiply by element size (assume 4 bytes)
        self._emit("    shl eax, 2")
        self._emit("    mov ebx, eax")
        self._emit("    pop eax")
        self._emit("    add eax, ebx")

        self._store_eax_to_dest(inst.dest)

    def _gen_phi(self, inst: MIRInstruction) -> None:
        """Generate phi node (simplified - just use first incoming)."""
        # Real SSA deconstruction would insert copies at predecessor ends
        # For now, use first incoming value
        if inst.phi_incoming:
            value, _ = inst.phi_incoming[0]
            self._load_value_to_eax(value)
            self._store_eax_to_dest(inst.dest)


def generate_x86_from_mir(module: MIRModule, kernel_mode: bool = False) -> str:
    """
    Convenience function to generate x86 from MIR.

    Args:
        module: MIR module
        kernel_mode: If True, don't generate _start

    Returns:
        x86 assembly string
    """
    codegen = MIRToX86(kernel_mode)
    return codegen.generate(module)


# ============================================================================
# Test
# ============================================================================

if __name__ == "__main__":
    from lexer import Lexer
    from parser import Parser
    from ast_to_mir import lower_to_mir

    code = """
proc add(a: int32, b: int32): int32 =
  return a + b

proc main() =
  var x: int32 = 10
  var y: int32 = 20
  var z: int32 = add(x, y)
  return
"""

    lexer = Lexer(code)
    tokens = lexer.tokenize()

    parser = Parser(tokens)
    ast = parser.parse()

    mir = lower_to_mir(ast)
    print("; MIR:")
    print(mir)
    print()

    asm = generate_x86_from_mir(mir)
    print("; x86 Assembly:")
    print(asm)
